a1a=['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']
a1b=2649
a1c=12.05988565013656
a1d='function'
a2a=13
a2b=2.4630453700815003
a4a3=0.8689827219809665
a4b1=[('``', '.'), ('My', 'DET'), ('taste', 'NOUN'), ('is', 'VERB'), ('gaudy', 'ADV'), ('.', '.')]
a4b2=[('``', '.'), ('My', 'DET'), ('taste', 'NOUN'), ('is', 'VERB'), ('gaudy', 'ADJ'), ('.', '.')]
a4b3="The HMM can only see 2-word histories, thus it can't see that the word 'gaudy' is actually an ADJ that describes the word 'taste'. The model tagged 'gaudy' as an ADV because 'gaudy' has a higher probability as an ADV and a VERB has a higher probability to be followed by an ADV."
a4c=56.630575309531835
a4d=308.7122785474796
a4e=['DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADV']
a5='To tag a sentence, we would need the transition and emission probabilities. For an unrecognised word, the emission probability will always be 0. However, if we make use of smoothing (e.g. by using the Lidstone estimator), it will address the problem by stealing probability mass from seen events and reallocating it to unseen events. Then, you will have a predicted tag assigned to the unrecognised word. The parsing algorithm should now be able to produce a parse for the well-formed sentence.'
a6="We converted the original Brown Corpus tagset to the Universal tagset because the Universal tagset has fewer tags. Having more tags means we're likely to have sparser data, i.e. the same word will have more different tags, thus that each (word, tag) pair will have less observations. This may cause lower confidence level on the probability model and accuracy on tag set will be much lower. The Universal tagset is more language agnostic (more generic) and will work better on other languages."
a3c=16.79319240474419
a3d='<s>'
